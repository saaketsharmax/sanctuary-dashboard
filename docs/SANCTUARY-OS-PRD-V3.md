# Sanctuary OS â€” Product Requirements Document

**Version:** 3.0
**Last Updated:** 2026-02-06
**Status:** Active Development

---

## Executive Summary

Sanctuary OS is an **AI-native startup accelerator platform** that transforms how accelerators evaluate, onboard, and support founders. The system uses a mesh of specialized AI agents that continuously improve through structured feedback loops, creating a flywheel where every interaction makes the platform smarter.

### Core Innovation

Traditional accelerators rely on:
- Manual application reviews (hours per application)
- Inconsistent interview quality
- Gut-feel scoring
- No systematic learning from outcomes

Sanctuary OS delivers:
- **AI-conducted interviews** that probe deeper than humans
- **Evidence-based scoring** with transparent reasoning
- **Self-calibrating assessments** that improve with every decision
- **Rich metadata collection** that enables continuous learning

---

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           SANCTUARY OS ARCHITECTURE                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚   FOUNDERS      â”‚
                              â”‚   (Applicants)  â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                      â”‚
                    â–¼                                      â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  Application    â”‚                   â”‚   AI Interview  â”‚
          â”‚  Form + Metadataâ”‚                   â”‚   Agent         â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚                                      â”‚
                   â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
                   â””â”€â”€â”€â–ºâ”‚  ENRICHED DATABASE   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚                      â”‚
                        â”‚  â€¢ Applications      â”‚
                        â”‚  â€¢ Transcripts       â”‚
                        â”‚  â€¢ Signals           â”‚
                        â”‚  â€¢ Metadata          â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                              â”‚
                    â–¼                              â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  Assessment     â”‚           â”‚  Programme      â”‚
          â”‚  Agent          â”‚           â”‚  Agent          â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚                              â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   PARTNERS      â”‚
                        â”‚   (Reviewers)   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Feedback Loop  â”‚
                        â”‚  â€¢ Agree/Overrideâ”‚
                        â”‚  â€¢ Score Adjust â”‚
                        â”‚  â€¢ Outcomes     â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Calibration    â”‚
                        â”‚  Engine         â”‚
                        â”‚  â€¢ Weight adjustâ”‚
                        â”‚  â€¢ Prompt refineâ”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## User Journeys

### Journey 1: Founder Application Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FOUNDER JOURNEY                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PHASE 1: DISCOVERY & SIGNUP
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Landing Page (/)
    â”‚
    â”œâ”€â”€ "Apply to Sanctuary" CTA
    â”‚
    â–¼
Authentication (/auth/signup)
    â”‚
    â”œâ”€â”€ Email/Password
    â”œâ”€â”€ Google OAuth
    â””â”€â”€ GitHub OAuth
    â”‚
    â–¼
Role Selection (/auth/role-select)
    â”‚
    â””â”€â”€ Select "I am a Founder"
    â”‚
    â–¼
Founder Dashboard (/founder/dashboard)


PHASE 2: APPLICATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Application Form (/founder/apply)
    â”‚
    â”œâ”€â”€ Step 1: Company Info
    â”‚   â€¢ Company name, one-liner
    â”‚   â€¢ Website, description
    â”‚   ğŸ“Š Metadata: time_on_step, edits_made
    â”‚
    â”œâ”€â”€ Step 2: Founders
    â”‚   â€¢ Names, roles, LinkedIn
    â”‚   â€¢ Experience, prior startups
    â”‚   ğŸ“Š Metadata: founder_count, experience_years
    â”‚
    â”œâ”€â”€ Step 3: Problem
    â”‚   â€¢ Problem description
    â”‚   â€¢ Target customer
    â”‚   ğŸ“Š Metadata: word_count, specificity_score
    â”‚
    â”œâ”€â”€ Step 4: Solution
    â”‚   â€¢ Solution description
    â”‚   â€¢ Current stage
    â”‚   ğŸ“Š Metadata: buzzword_density
    â”‚
    â”œâ”€â”€ Step 5: Traction
    â”‚   â€¢ User count, MRR
    â”‚   â€¢ Biggest challenge
    â”‚   ğŸ“Š Metadata: metrics_mentioned
    â”‚
    â””â”€â”€ Step 6: Fit
        â€¢ Why Sanctuary
        â€¢ What they want
        ğŸ“Š Metadata: total_time, red_flags, green_flags
    â”‚
    â–¼
Application Submitted
    â”‚
    â””â”€â”€ Status: "submitted"
        Database: applications table
        Metadata: application_metadata (JSONB)


PHASE 3: AI INTERVIEW
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Interview Start (/founder/interview/[id])
    â”‚
    â”œâ”€â”€ API: POST /api/applications/[id]/interview {action: "start"}
    â”‚   â””â”€â”€ Status â†’ "interviewing"
    â”‚   â””â”€â”€ interview_started_at recorded
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INTERVIEW AGENT (Claude)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Section 1: FOUNDER DNA (10-15 min)                             â”‚
â”‚  â”œâ”€â”€ "Tell me about yourself in 60 seconds"                     â”‚
â”‚  â”œâ”€â”€ "What's the hardest thing you've overcome?"                â”‚
â”‚  â”œâ”€â”€ "How do you and your co-founder resolve disagreements?"    â”‚
â”‚  â””â”€â”€ ğŸ“Š Signals: prior_exit, domain_expertise, grit             â”‚
â”‚                                                                  â”‚
â”‚  Section 2: PROBLEM INTERROGATION (10-15 min)                   â”‚
â”‚  â”œâ”€â”€ "How do you know this problem is real?"                    â”‚
â”‚  â”œâ”€â”€ "Tell me about a specific customer conversation"           â”‚
â”‚  â”œâ”€â”€ "What happens if they don't solve this?"                   â”‚
â”‚  â””â”€â”€ ğŸ“Š Signals: customer_discovery, pain_quotes, frequency     â”‚
â”‚                                                                  â”‚
â”‚  Section 3: SOLUTION EXECUTION (10 min)                         â”‚
â”‚  â”œâ”€â”€ "Walk me through how it works"                             â”‚
â”‚  â”œâ”€â”€ "What have you built vs what's planned?"                   â”‚
â”‚  â”œâ”€â”€ "What did you cut and why?"                                â”‚
â”‚  â””â”€â”€ ğŸ“Š Signals: shipping_speed, smart_cuts, technical_moat     â”‚
â”‚                                                                  â”‚
â”‚  Section 4: MARKET COMPETITION (5-10 min)                       â”‚
â”‚  â”œâ”€â”€ "Who else is solving this?"                                â”‚
â”‚  â”œâ”€â”€ "Why will you win?"                                        â”‚
â”‚  â””â”€â”€ ğŸ“Š Signals: market_awareness, differentiation              â”‚
â”‚                                                                  â”‚
â”‚  Section 5: SANCTUARY FIT (5 min)                               â”‚
â”‚  â”œâ”€â”€ "What do you need most right now?"                         â”‚
â”‚  â”œâ”€â”€ "What does success look like in 6 months?"                 â”‚
â”‚  â””â”€â”€ ğŸ“Š Signals: self_awareness, coachability                   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
Interview Complete
    â”‚
    â”œâ”€â”€ API: POST /api/applications/[id]/interview {action: "complete"}
    â”‚   â”œâ”€â”€ transcript saved as JSONB
    â”‚   â”œâ”€â”€ signals saved to interview_signals table
    â”‚   â”œâ”€â”€ interview_metadata computed and saved
    â”‚   â””â”€â”€ Status â†’ "under_review"
    â”‚
    â–¼
Complete Page (/founder/interview/[id]/complete)
    â”‚
    â””â”€â”€ "Thank you! We'll respond within 48 hours"


PHASE 4: ASSESSMENT (AI-Generated)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Assessment Agent (Automatic)
    â”‚
    â”œâ”€â”€ Input: transcript + signals + application_metadata
    â”‚
    â”œâ”€â”€ Output:
    â”‚   â”œâ”€â”€ Founder Score (0-100) + reasoning
    â”‚   â”œâ”€â”€ Problem Score (0-100) + reasoning
    â”‚   â”œâ”€â”€ User Value Score (0-100) + reasoning
    â”‚   â”œâ”€â”€ Execution Score (0-100) + reasoning
    â”‚   â”œâ”€â”€ Overall Score (weighted)
    â”‚   â”œâ”€â”€ Recommendation (accept/conditional/decline)
    â”‚   â”œâ”€â”€ Key Strengths (with evidence)
    â”‚   â”œâ”€â”€ Key Risks (with severity)
    â”‚   â”œâ”€â”€ Critical Questions for partner
    â”‚   â””â”€â”€ Confidence levels per dimension
    â”‚
    â””â”€â”€ Saved: ai_assessment (JSONB), ai_score, assessment_metadata


PHASE 5: DECISION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Partner Review â†’ Decision
    â”‚
    â”œâ”€â”€ If ACCEPTED:
    â”‚   â”œâ”€â”€ Status â†’ "accepted"
    â”‚   â”œâ”€â”€ Startup record created
    â”‚   â”œâ”€â”€ Founder linked to startup
    â”‚   â””â”€â”€ Full dashboard access granted
    â”‚
    â””â”€â”€ If REJECTED:
        â”œâ”€â”€ Status â†’ "rejected"
        â””â”€â”€ Founder notified


PHASE 6: POST-ACCEPTANCE (Active Founders)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
/founder/dashboard    â†’ Overview, quick actions
/founder/company      â†’ Edit company profile
/founder/documents    â†’ Upload pitch decks, financials
/founder/progress     â†’ Track milestones, checkpoints
/founder/metrics      â†’ View metrics shared by partners
/founder/requests     â†’ Request mentor help, features
/founder/settings     â†’ Account settings
```

---

### Journey 2: Partner Review Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PARTNER JOURNEY                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PHASE 1: AUTHENTICATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
/auth/login â†’ /auth/role-select â†’ "I am a Partner"
    â”‚
    â””â”€â”€ Select sub-type:
        â”œâ”€â”€ Mentor (focus: mentorship matching)
        â”œâ”€â”€ VC (focus: investment metrics)
        â””â”€â”€ Startup Manager (full access)


PHASE 2: APPLICATION REVIEW
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
/partner/applications
    â”‚
    â”œâ”€â”€ Application List
    â”‚   â”œâ”€â”€ Filter by status (submitted, interviewing, under_review)
    â”‚   â”œâ”€â”€ Sort by date, score
    â”‚   â””â”€â”€ Quick stats (AI score, stage, MRR)
    â”‚
    â–¼
/partner/applications/[id]
    â”‚
    â”œâ”€â”€ TAB 1: Overview
    â”‚   â”œâ”€â”€ Company info card
    â”‚   â”œâ”€â”€ Founder cards (experience, LinkedIn)
    â”‚   â”œâ”€â”€ Problem/Solution summary
    â”‚   â””â”€â”€ Application metadata insights
    â”‚
    â”œâ”€â”€ TAB 2: Interview
    â”‚   â”œâ”€â”€ Full transcript viewer
    â”‚   â”œâ”€â”€ Section navigation (jump to Founder DNA, etc.)
    â”‚   â”œâ”€â”€ Highlighted quotes (from signals)
    â”‚   â”œâ”€â”€ Behavioral insights
    â”‚   â”‚   â”œâ”€â”€ Response time patterns
    â”‚   â”‚   â”œâ”€â”€ Pause frequency
    â”‚   â”‚   â””â”€â”€ Answer depth per section
    â”‚   â””â”€â”€ Interview metadata display
    â”‚
    â”œâ”€â”€ TAB 3: Assessment
    â”‚   â”œâ”€â”€ Overall score (large, color-coded)
    â”‚   â”œâ”€â”€ Dimension scores with progress bars
    â”‚   â”‚   â”œâ”€â”€ Founder: 82 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘
    â”‚   â”‚   â”œâ”€â”€ Problem: 78 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘
    â”‚   â”‚   â”œâ”€â”€ User Value: 72 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘
    â”‚   â”‚   â””â”€â”€ Execution: 80 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘
    â”‚   â”œâ”€â”€ Reasoning for each score
    â”‚   â”œâ”€â”€ Confidence indicators
    â”‚   â”œâ”€â”€ Key Strengths (expandable cards)
    â”‚   â”œâ”€â”€ Key Risks (with severity badges)
    â”‚   â”œâ”€â”€ Critical Questions
    â”‚   â””â”€â”€ Evidence density indicator
    â”‚
    â”œâ”€â”€ TAB 4: Programme
    â”‚   â”œâ”€â”€ Proposed starting stage
    â”‚   â”œâ”€â”€ Recommended duration
    â”‚   â”œâ”€â”€ Success metrics
    â”‚   â”œâ”€â”€ Conditions for acceptance
    â”‚   â”œâ”€â”€ Mentor recommendations
    â”‚   â””â”€â”€ Weekly milestone preview
    â”‚
    â””â”€â”€ ACTIONS
        â”œâ”€â”€ [Approve] â†’ Confirmation modal
        â”‚   â”œâ”€â”€ Optional conditions
        â”‚   â””â”€â”€ Notes for founder
        â”‚
        â””â”€â”€ [Reject] â†’ Confirmation modal
            â”œâ”€â”€ Reason selection
            â””â”€â”€ Optional feedback


PHASE 3: FEEDBACK COLLECTION (Critical for Learning)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
After Decision:
    â”‚
    â”œâ”€â”€ Agreement Checkboxes
    â”‚   â”œâ”€â”€ â˜‘ Agree with recommendation
    â”‚   â”œâ”€â”€ â˜‘ Agree with Founder score
    â”‚   â”œâ”€â”€ â˜ Agree with Problem score (override: 80)
    â”‚   â”œâ”€â”€ â˜‘ Agree with User Value score
    â”‚   â””â”€â”€ â˜‘ Agree with Execution score
    â”‚
    â”œâ”€â”€ Qualitative Feedback
    â”‚   â”œâ”€â”€ "What did AI miss?"
    â”‚   â””â”€â”€ "What did AI overweight?"
    â”‚
    â””â”€â”€ Saved to: assessment_feedback table
        â””â”€â”€ Used for: calibration, weight adjustment


PHASE 4: PORTFOLIO MANAGEMENT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
/partner/portfolio         â†’ Grid/list of active startups
/partner/portfolio/[id]    â†’ Startup detail page
/partner/metrics           â†’ Portfolio-wide metrics dashboard
/partner/mentors           â†’ Mentor database
/partner/matches           â†’ Mentor-startup matching
/partner/shared-views      â†’ Control what founders see
```

---

## AI Agent Specifications

### Agent 1: Interview Agent

**Purpose:** Conduct structured, probing interviews that extract maximum signal from founders.

**Technology:**
- Model: Claude Sonnet 4 (claude-sonnet-4-20250514)
- Integration: Anthropic API via `@anthropic-ai/sdk`
- Response format: Structured JSON with response + signals

**Capabilities:**
- Maintains conversation context across sections
- Probes vague answers ("Can you be more specific?")
- Extracts signals in real-time with confidence scores
- Adapts questions based on previous answers
- Knows when to transition between sections
- Handles interview pause/resume

**Output per message:**
```typescript
{
  response: string,           // The actual message to founder
  shouldTransition: boolean,  // Move to next section?
  isComplete: boolean,        // Interview finished?
  signals: [
    {
      type: "founder_signal" | "problem_signal" | "risk_flag" | ...,
      content: "Prior exit to GitLab demonstrates execution ability",
      dimension: "founder" | "problem" | "user_value" | "execution",
      impact: +15  // -5 to +5 scale
    }
  ]
}
```

**Behavioral Metadata Collected:**
- Response times per question
- Pause frequency and duration
- Answer length patterns
- Clarification questions asked
- Topic coverage vs gaps

---

### Agent 2: Assessment Agent

**Purpose:** Analyze interview transcript and generate structured, evidence-based assessment.

**Input:**
- Full interview transcript
- Extracted signals with metadata
- Application form data
- Application metadata (content analysis, flags)

**Output:**
```typescript
{
  // Scores
  founderScore: 82,
  problemScore: 78,
  userValueScore: 72,
  executionScore: 80,
  overallScore: 78,  // Weighted: FÃ—0.30 + PÃ—0.25 + UVÃ—0.25 + EÃ—0.20

  // Recommendation
  recommendation: "accept" | "conditional" | "decline",
  recommendationConfidence: 0.85,

  // Reasoning
  founderReasoning: "Michael has a prior exit (GitLab acquisition)...",
  problemReasoning: "47 customer discovery calls with specific quotes...",
  userValueReasoning: "12 paying users at $200/month average...",
  executionReasoning: "8 months to first paying customer...",

  // Evidence
  keyStrengths: [
    { strength: "Founder-problem fit", evidence: "...", impact: "..." }
  ],
  keyRisks: [
    { risk: "GTM inexperience", evidence: "...", severity: "medium", mitigation: "..." }
  ],
  criticalQuestions: ["Can they hire enterprise sales?", ...],

  // Needs
  primaryNeed: "GTM strategy and sales process",
  mentorDomains: ["B2B Sales", "Developer Tools GTM"],

  // Metadata
  assessmentMetadata: {
    confidence: { overall: 0.82, founder: 0.88, ... },
    evidenceDensity: { founder: { positive: 5, negative: 1, ... }, ... },
    gapsIdentified: [{ dimension: "user_value", missing: "retention_rate" }],
    scoringBreakdown: { founder: { base: 50, signals: [...], final: 82 } }
  }
}
```

**Scoring Methodology:**
- Base score: 50 (neutral)
- Each signal adds/subtracts based on `signal_weights` table
- Diminishing returns (3rd similar signal worth less)
- Confidence adjusted by evidence density
- Missing information lowers confidence, not score

---

### Agent 3: Programme Agent (Planned)

**Purpose:** Generate personalized programme recommendations based on assessment.

**Output:**
- Starting stage (Problem â†’ User Value â†’ Execution â†’ Scale)
- Duration recommendation
- Weekly milestones with tasks
- Checkpoint questions
- Mentor matching recommendations
- Success metrics and conditions

---

### Agent 4: Calibration Engine (Planned)

**Purpose:** Continuously improve agent accuracy using feedback and outcomes.

**Inputs:**
- Partner feedback (agreement, score adjustments)
- Startup outcomes (3/6/12 month checkpoints)
- Signal extraction patterns

**Actions:**
- Adjust signal weights based on outcome correlation
- Refine prompts based on partner overrides
- Flag calibration drift alerts
- Generate weekly calibration reports

---

## Data Model

### Core Tables

```sql
-- Users (extends Supabase auth)
users
â”œâ”€â”€ id (UUID, PK, FK â†’ auth.users)
â”œâ”€â”€ email
â”œâ”€â”€ name
â”œâ”€â”€ avatar_url
â”œâ”€â”€ user_type ('founder' | 'partner')
â”œâ”€â”€ partner_sub_type ('mentor' | 'vc' | 'startup_manager')
â”œâ”€â”€ startup_id (FK â†’ startups, for founders)
â”œâ”€â”€ onboarding_complete
â””â”€â”€ timestamps

-- Applications (rich with metadata)
applications
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ user_id (FK â†’ users)
â”œâ”€â”€ status ('draft' | 'submitted' | 'interviewing' | 'under_review' | 'accepted' | 'rejected')
â”‚
â”œâ”€â”€ -- Core Data
â”œâ”€â”€ company_name, company_one_liner, company_website
â”œâ”€â”€ problem_description, target_customer, solution_description
â”œâ”€â”€ stage, user_count, mrr
â”œâ”€â”€ biggest_challenge, why_sanctuary, what_they_want
â”œâ”€â”€ founders (JSONB array)
â”‚
â”œâ”€â”€ -- Interview Data
â”œâ”€â”€ interview_started_at, interview_completed_at
â”œâ”€â”€ interview_transcript (JSONB)
â”œâ”€â”€ interview_metadata (JSONB) â† Behavioral signals, response patterns
â”‚
â”œâ”€â”€ -- Assessment Data
â”œâ”€â”€ ai_assessment (JSONB)
â”œâ”€â”€ ai_score (DECIMAL)
â”œâ”€â”€ assessment_metadata (JSONB) â† Confidence, evidence density
â”‚
â”œâ”€â”€ -- Review Data
â”œâ”€â”€ reviewed_by, reviewed_at, review_decision
â”œâ”€â”€ review_metadata (JSONB) â† Partner feedback, adjustments
â”‚
â”œâ”€â”€ -- Tracking
â”œâ”€â”€ application_metadata (JSONB) â† Form behavior, content analysis
â””â”€â”€ timestamps

-- Interview Signals (for analysis)
interview_signals
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ application_id (FK)
â”œâ”€â”€ signal_type, dimension
â”œâ”€â”€ content, source_quote
â”œâ”€â”€ impact_score (-5 to +5)
â”œâ”€â”€ signal_metadata (JSONB) â† Confidence, corroboration
â””â”€â”€ created_at

-- Assessment Feedback (for calibration)
assessment_feedback
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ application_id (FK)
â”œâ”€â”€ partner_id (FK)
â”œâ”€â”€ agrees_with_* (booleans)
â”œâ”€â”€ adjusted_*_score (integers)
â”œâ”€â”€ what_ai_missed, what_ai_overweighted
â”œâ”€â”€ feedback_metadata (JSONB)
â””â”€â”€ created_at

-- Startup Outcomes (for validation)
startup_outcomes
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ startup_id (FK)
â”œâ”€â”€ application_id (FK)
â”œâ”€â”€ three_month_*, six_month_*, twelve_month_* (checkpoints)
â”œâ”€â”€ outcome ('graduated_success' | 'failed' | 'acquired' | ...)
â”œâ”€â”€ outcome_metadata (JSONB) â† Risk materialization, learnings
â””â”€â”€ timestamps

-- Signal Weights (for calibration)
signal_weights
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ signal_type, dimension
â”œâ”€â”€ base_weight, computed_weight, active_weight
â”œâ”€â”€ correlation_with_success
â”œâ”€â”€ version, effective_from, effective_to
â”œâ”€â”€ weight_metadata (JSONB)
â””â”€â”€ timestamps

-- Agent Runs (audit trail)
agent_runs
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ agent_type ('interview' | 'assessment' | 'programme' | ...)
â”œâ”€â”€ application_id, startup_id
â”œâ”€â”€ status, started_at, completed_at
â”œâ”€â”€ input_summary, output_summary
â”œâ”€â”€ run_metadata (JSONB) â† Token usage, latency, errors
â””â”€â”€ created_at
```

---

## Metadata Structures

### Application Metadata
```typescript
{
  source: {
    referral_code, utm_source, utm_campaign, landing_page
  },
  form_behavior: {
    started_at, completed_at, total_time_seconds,
    time_per_step: { company: 120, founders: 340, ... },
    steps_revisited: ["problem"],
    fields_edited_after_initial: ["mrr"],
    device_type, browser
  },
  content_analysis: {
    total_word_count: 1240,
    specificity_score: 0.78,
    buzzword_density: 0.12,
    metrics_mentioned: ["$2400 MRR", "12 users"],
    named_entities: ["GitLab", "Stripe"]
  },
  red_flags_detected: [
    { type: "inconsistency", description: "MRR doesn't match...", severity: "low" }
  ],
  green_flags_detected: [
    { type: "repeat_founder", description: "Team includes...", confidence: 0.9 }
  ]
}
```

### Interview Metadata
```typescript
{
  session: {
    duration_minutes: 52,
    total_messages: 47,
    pauses_taken: 2,
    total_pause_time_seconds: 340
  },
  sections: {
    founder_dna: {
      messages: 10,
      avg_response_time_seconds: 45,
      avg_response_length: 89,
      topic_coverage: ["background", "motivation"],
      topics_missed: ["failure_experience"]
    },
    // ... other sections
  },
  behavioral_signals: {
    response_time_pattern: "consistent",
    longest_response_time: { seconds: 180, question: "..." },
    questions_asked_to_clarify: 2,
    emotional_markers: ["enthusiasm:high"]
  },
  content_quality: {
    specific_examples_given: 12,
    vague_answers_count: 3,
    data_points_shared: 8,
    customer_quotes_shared: 4
  }
}
```

### Assessment Metadata
```typescript
{
  model_used: "claude-sonnet-4-20250514",
  prompt_version: "v2.3",
  scoring_rubric_version: "v1.0",

  confidence: {
    overall: 0.82,
    founder: 0.88,
    problem: 0.75,
    user_value: 0.79,
    execution: 0.85
  },

  evidence_density: {
    founder: { positive_signals: 5, negative_signals: 1, quotes: 3 }
  },

  gaps_identified: [
    { dimension: "user_value", missing_info: "retention_rate", impact: -0.15 }
  ],

  scoring_breakdown: {
    founder: {
      base_score: 50,
      signals_applied: [
        { signal: "prior_exit", impact: +15 },
        { signal: "domain_expertise", impact: +8 }
      ],
      final_score: 82
    }
  }
}
```

---

## Scoring System

### Dimension Weights
| Dimension | Weight | Rationale |
|-----------|--------|-----------|
| Founder | 30% | Most predictive of success per research |
| Problem | 25% | 42% of startups fail due to no market need |
| User Value | 25% | Evidence of product-market fit |
| Execution | 20% | Shipping speed and decision quality |

### Signal Examples

**Founder Signals:**
| Signal | Impact | Example |
|--------|--------|---------|
| Prior exit | +15 | "We sold to GitLab" |
| Domain expertise (years) | +2/yr | "8 years in DevOps" |
| Relevant company | +5 | "I was at Stripe" |
| Adversity overcome | +5 | "We ran out of money and..." |
| Blames external | -10 | "The market wasn't ready" |
| Gives up easily | -15 | Pattern of abandonment |

**Problem Signals:**
| Signal | Impact | Example |
|--------|--------|---------|
| Customer calls (qty) | +1/call | "47 interviews" |
| Specific pain quote | +5 each | "CTO said 'I'd pay $10k'" |
| Quantified pain | +10 | "20% of sprints lost" |
| Personal experience | +5 | "I dealt with this for 3 years" |
| No validation | -15 | "Haven't talked to customers" |

### Recommendation Thresholds
| Score Range | Recommendation | Action |
|-------------|----------------|--------|
| 85+ | Strong Accept | Fast-track |
| 75-84 | Accept | Standard process |
| 65-74 | Conditional | Requires discussion |
| 55-64 | Lean Decline | Usually reject |
| <55 | Decline | Auto-reject consideration |

---

## Self-Improvement Flywheel

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CONTINUOUS IMPROVEMENT LOOP                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Application â”‚
    â”‚  Submitted   â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Interview   â”‚â”€â”€â”€â”€â–º Signals extracted with confidence
    â”‚  Completed   â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Assessment  â”‚â”€â”€â”€â”€â–º Scores generated with evidence
    â”‚  Generated   â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Partner     â”‚â”€â”€â”€â”€â–º Agreement/Override recorded
    â”‚  Review      â”‚      â””â”€â”€ assessment_feedback table
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Decision    â”‚â”€â”€â”€â”€â–º Outcome baseline set
    â”‚  Made        â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  3/6/12 Mo   â”‚â”€â”€â”€â”€â–º Actual outcomes recorded
    â”‚  Checkpoints â”‚      â””â”€â”€ startup_outcomes table
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 CALIBRATION ENGINE                    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                       â”‚
    â”‚  1. Compare predictions to outcomes                   â”‚
    â”‚     â””â”€â”€ Which signals correlated with success?        â”‚
    â”‚                                                       â”‚
    â”‚  2. Analyze partner overrides                         â”‚
    â”‚     â””â”€â”€ Where does AI systematically miss?            â”‚
    â”‚                                                       â”‚
    â”‚  3. Adjust signal weights                             â”‚
    â”‚     â””â”€â”€ Update signal_weights table                   â”‚
    â”‚                                                       â”‚
    â”‚  4. Refine prompts                                    â”‚
    â”‚     â””â”€â”€ Better question sequencing                    â”‚
    â”‚                                                       â”‚
    â”‚  5. Flag calibration drift                            â”‚
    â”‚     â””â”€â”€ Alert if AI/human agreement drops             â”‚
    â”‚                                                       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  Improved Agents  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Back to top
```

### Calibration Metrics

**Weekly Dashboard:**
- AI/Partner agreement rate (target: >80%)
- Score drift per dimension
- Signal effectiveness rankings
- Confidence calibration (are 85% confident predictions right 85% of the time?)

**Quarterly Review:**
- Outcome correlation analysis
- Weight adjustment recommendations
- Prompt refinement suggestions
- New signal discovery

---

## Technical Stack

### Frontend
- **Framework:** Next.js 15 (App Router)
- **Language:** TypeScript
- **Styling:** Tailwind CSS + shadcn/ui
- **State:** Zustand with persistence
- **Forms:** React Hook Form + Zod

### Backend
- **API:** Next.js API Routes
- **Database:** Supabase (PostgreSQL)
- **Auth:** Supabase Auth (Email, Google, GitHub)
- **AI:** Anthropic Claude API

### Infrastructure
- **Monorepo:** Turborepo
- **Hosting:** Vercel
- **Database:** Supabase Cloud
- **Monitoring:** Vercel Analytics

---

## Current Implementation Status

### âœ… Completed

| Feature | Status | Notes |
|---------|--------|-------|
| Auth System | âœ… | Email/password, role selection |
| Founder Dashboard | âœ… | All pages with mock data |
| Partner Dashboard | âœ… | All pages with mock data |
| Application Form | âœ… | 6-step form, saves to Supabase |
| Interview Agent | âœ… | Claude API integration |
| Interview â†’ DB | âœ… | Transcript + signals saved |
| Partner Review UI | âœ… | 4-tab detail view |
| Enriched Schema | âœ… | All metadata tables |
| Metadata Collection | âœ… | Application + Interview metadata |

### ğŸ”„ In Progress

| Feature | Status | Notes |
|---------|--------|-------|
| Assessment Agent | ğŸ”„ | Next priority |
| Partner Feedback UI | ğŸ”„ | Feedback collection |

### ğŸ“‹ Planned

| Feature | Priority | Notes |
|---------|----------|-------|
| Programme Agent | P1 | Milestone generation |
| Calibration Engine | P1 | Weight adjustment |
| Outcome Tracking UI | P1 | Checkpoint recording |
| Real-time Updates | P2 | Supabase subscriptions |
| Analytics Dashboard | P2 | Calibration metrics |
| Matching Agent | P2 | Mentor-startup matching |

---

## Success Metrics

### Platform Metrics
- **Application-to-interview rate:** >90%
- **Interview completion rate:** >85%
- **Time to decision:** <48 hours
- **Partner review time:** <15 min per application

### AI Quality Metrics
- **AI/Partner agreement:** >80%
- **Score prediction accuracy:** Within 10 points of partner adjustment
- **Confidence calibration:** 85% confident = 85% accurate

### Outcome Metrics
- **Accepted startup survival (12mo):** >70%
- **Graduated startup success rate:** >40%
- **Signal-to-outcome correlation:** Statistically significant

---

## Appendix: API Reference

### Application Endpoints

```
POST   /api/applications                 Create application
GET    /api/applications                 List user's applications
POST   /api/applications/[id]/interview  Start/complete interview
GET    /api/applications/[id]/interview  Get interview data
```

### Interview Endpoints

```
POST   /api/interview/chat               Send message, get AI response
```

### Upcoming Endpoints

```
POST   /api/applications/[id]/assess     Trigger assessment
GET    /api/applications/[id]/assessment Get assessment
POST   /api/applications/[id]/feedback   Submit partner feedback
POST   /api/applications/[id]/decision   Record accept/reject
GET    /api/calibration/metrics          Get calibration dashboard
```

---

*This document is the source of truth for Sanctuary OS product requirements. Update version number and date when making changes.*
